{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUnkaP6ylEgS",
        "outputId": "0afd919d-ebd1-49b2-a524-f96557145faa",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.12/dist-packages (1.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Collecting stable-baselines3[extra]\n",
            "  Downloading stable_baselines3-2.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (4.12.0.88)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (2.6.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (13.9.4)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (0.11.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (11.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboard) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (5.29.5)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->stable-baselines3[extra]) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->stable-baselines3[extra]) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Downloading stable_baselines3-2.7.0-py3-none-any.whl (187 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m187.2/187.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: stable-baselines3\n",
            "Successfully installed stable-baselines3-2.7.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install numpy pandas scikit-learn gymnasium torch stable-baselines3[extra] tensorboard\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "mWPsQgizlbgW",
        "outputId": "59af7bdf-89af-4950-8132-8cd5c0945284",
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3dad09ed-6ff1-460f-b0ca-1eefd094179e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3dad09ed-6ff1-460f-b0ca-1eefd094179e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving cars.csv to cars.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# PPO DEALERSHIP RL WITH:\n",
        "# - Relative Scoring\n",
        "# - Preference Strictness\n",
        "# - Hard Budget Constraints\n",
        "# - Refinement Ranking\n",
        "# - Explanations\n",
        "# ============================================================\n",
        "\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 1. LOAD DATA\n",
        "# ============================================================\n",
        "\n",
        "df = pd.read_csv(\"cars.csv\")\n",
        "\n",
        "num_cols = [\"price\", \"horsepower\", \"torque\", \"seats\"]\n",
        "cat_cols = [\"brand\", \"body_type\", \"fuel_type\"]\n",
        "\n",
        "preprocess = ColumnTransformer([\n",
        "    (\"num\", MinMaxScaler(), num_cols),\n",
        "    (\"cat\", OneHotEncoder(), cat_cols),\n",
        "])\n",
        "\n",
        "X = preprocess.fit_transform(df)\n",
        "X = X.toarray().astype(np.float32)\n",
        "\n",
        "N_CARS = len(df)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 2. CUSTOMER GENERATOR WITH STRICTNESS LEVELS\n",
        "# ============================================================\n",
        "\n",
        "def generate_customer():\n",
        "    return {\n",
        "        \"budget\": np.random.uniform(0.1, 1.0),\n",
        "        \"power_pref\": np.random.uniform(0.0, 1.0),\n",
        "        \"family_size\": np.random.randint(1, 7),\n",
        "        \"body_pref\": np.random.choice(df[\"body_type\"].unique()),\n",
        "        \"fuel_pref\": np.random.choice(df[\"fuel_type\"].unique()),\n",
        "        \"patience\": 4,\n",
        "\n",
        "        # NEW: Preference strictness\n",
        "        \"strictness\": {\n",
        "            \"body\": np.random.choice([\"must\", \"strong\", \"soft\"]),\n",
        "            \"fuel\": np.random.choice([\"must\", \"strong\", \"soft\"]),\n",
        "            \"power\": np.random.choice([\"strong\", \"soft\"]),\n",
        "            \"budget\": np.random.choice([\"must\", \"strong\"]),\n",
        "            \"seats\": np.random.choice([\"must\", \"strong\"])\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 3. MATCH SCORE (BASE SCORE)\n",
        "# ============================================================\n",
        "\n",
        "def match_score(customer, car_vector, car_row):\n",
        "    score = 0\n",
        "    hp_norm = car_row[\"horsepower\"] / df[\"horsepower\"].max()\n",
        "    price_norm = car_row[\"price\"] / df[\"price\"].max()\n",
        "\n",
        "    score += 1 - abs(hp_norm - customer[\"power_pref\"])\n",
        "    score += 1 - abs(price_norm - customer[\"budget\"])\n",
        "    score += 1 if car_row[\"body_type\"] == customer[\"body_pref\"] else 0\n",
        "    score += 1 if car_row[\"fuel_type\"] == customer[\"fuel_pref\"] else 0\n",
        "    score += 1 if car_row[\"seats\"] >= customer[\"family_size\"] else 0\n",
        "\n",
        "    return score / 5\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 4. REFINEMENT (TOP-N FILTERING)\n",
        "# ============================================================\n",
        "\n",
        "def refined_best_pick(customer, top=5):\n",
        "    scores = []\n",
        "\n",
        "    for i in range(N_CARS):\n",
        "        car = df.iloc[i]\n",
        "\n",
        "        # Hard budget constraint: price > budget*1.35 = filtered out\n",
        "        if abs((car[\"price\"] / df[\"price\"].max()) - customer[\"budget\"]) > 0.35:\n",
        "            continue\n",
        "\n",
        "        score = match_score(customer, X[i], car)\n",
        "        scores.append((i, score))\n",
        "\n",
        "    if not scores:\n",
        "        # fallback: no constraints\n",
        "        for i in range(N_CARS):\n",
        "            car = df.iloc[i]\n",
        "            score = match_score(customer, X[i], car)\n",
        "            scores.append((i, score))\n",
        "\n",
        "    scores.sort(key=lambda x: x[1], reverse=True)\n",
        "    return scores[:top]\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 5. EXPLANATION SYSTEM\n",
        "# ============================================================\n",
        "\n",
        "def explain_recommendation(customer, car):\n",
        "    s = customer[\"strictness\"]\n",
        "    print(\"\\nüìò WHY THIS CAR:\")\n",
        "\n",
        "    # Body type\n",
        "    if car[\"body_type\"] == customer[\"body_pref\"]:\n",
        "        print(\"‚úî Matches your preferred body type\")\n",
        "    else:\n",
        "        print(\"‚úñ Body type mismatch (preference =\", s[\"body\"], \")\")\n",
        "\n",
        "    # Fuel\n",
        "    if car[\"fuel_type\"] == customer[\"fuel_pref\"]:\n",
        "        print(\"‚úî Fuel preference matched\")\n",
        "    else:\n",
        "        print(\"‚úñ Fuel mismatch (preference =\", s[\"fuel\"], \")\")\n",
        "\n",
        "    # Budget\n",
        "    price_norm = car[\"price\"] / df[\"price\"].max()\n",
        "    if price_norm <= customer[\"budget\"] + 0.15:\n",
        "        print(\"‚úî Price aligns with your budget preference\")\n",
        "    else:\n",
        "        print(\"‚úñ Price is higher than preferred (budget strict =\", s[\"budget\"], \")\")\n",
        "\n",
        "    # Seating\n",
        "    if car[\"seats\"] >= customer[\"family_size\"]:\n",
        "        print(\"‚úî Enough seats for your family\")\n",
        "    else:\n",
        "        print(\"‚úñ Not enough seats (strict =\", s[\"seats\"], \")\")\n",
        "\n",
        "    # Performance\n",
        "    hp_norm = car[\"horsepower\"] / df[\"horsepower\"].max()\n",
        "    if abs(hp_norm - customer[\"power_pref\"]) < 0.2:\n",
        "        print(\"‚úî Power output close to desired level\")\n",
        "    else:\n",
        "        print(\"‚úñ Power output differs from preferred level\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 6. ENVIRONMENT WITH STRICTNESS + HARD BUDGET PENALTY\n",
        "# ============================================================\n",
        "\n",
        "class CarDealershipEnv(gym.Env):\n",
        "    metadata = {\"render_modes\": []}\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.action_space = gym.spaces.Discrete(N_CARS)\n",
        "        self.observation_space = gym.spaces.Box(0, 1, shape=(6,), dtype=np.float32)\n",
        "        self.reset()\n",
        "\n",
        "    def _get_state(self):\n",
        "        body_idx = list(df[\"body_type\"].unique()).index(self.customer[\"body_pref\"]) / len(df[\"body_type\"].unique())\n",
        "        fuel_idx = list(df[\"fuel_type\"].unique()).index(self.customer[\"fuel_pref\"]) / len(df[\"fuel_type\"].unique())\n",
        "\n",
        "        return np.array([\n",
        "            self.customer[\"budget\"],\n",
        "            self.customer[\"power_pref\"],\n",
        "            self.customer[\"family_size\"] / 7,\n",
        "            body_idx,\n",
        "            fuel_idx,\n",
        "            self.customer[\"patience\"] / 4\n",
        "        ], dtype=np.float32)\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.customer = generate_customer()\n",
        "\n",
        "        # Compute relative max score\n",
        "        self.max_score = max(match_score(self.customer, X[i], df.iloc[i]) for i in range(N_CARS))\n",
        "        return self._get_state(), {}\n",
        "\n",
        "    def step(self, action):\n",
        "        car = df.iloc[action]\n",
        "        car_vec = X[action]\n",
        "        c = self.customer\n",
        "        s = c[\"strictness\"]\n",
        "\n",
        "        score = match_score(c, car_vec, car)\n",
        "        norm = score / self.max_score\n",
        "\n",
        "        reward = norm * 3 - 0.1\n",
        "        done = False\n",
        "\n",
        "        # Strictness penalties:\n",
        "        # Body type\n",
        "        if car[\"body_type\"] != c[\"body_pref\"]:\n",
        "            if s[\"body\"] == \"must\":\n",
        "                reward -= 1.0\n",
        "            elif s[\"body\"] == \"strong\":\n",
        "                reward -= 0.5\n",
        "            else:\n",
        "                reward -= 0.2\n",
        "\n",
        "        # Fuel type\n",
        "        if car[\"fuel_type\"] != c[\"fuel_pref\"]:\n",
        "            if s[\"fuel\"] == \"must\":\n",
        "                reward -= 1.0\n",
        "            elif s[\"fuel\"] == \"strong\":\n",
        "                reward -= 0.5\n",
        "            else:\n",
        "                reward -= 0.1\n",
        "\n",
        "        # Hard budget constraint\n",
        "        price_norm = car[\"price\"] / df[\"price\"].max()\n",
        "        if abs(price_norm - c[\"budget\"]) > 0.35:\n",
        "            reward -= 1.2\n",
        "\n",
        "        # Success condition\n",
        "        if norm >= 0.95:\n",
        "            reward += 6\n",
        "            done = True\n",
        "        else:\n",
        "            c[\"patience\"] -= 1\n",
        "\n",
        "        if c[\"patience\"] <= 0:\n",
        "            reward -= 2\n",
        "            done = True\n",
        "\n",
        "        return self._get_state(), reward, done, False, {}\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 7. TRAIN PPO\n",
        "# ============================================================\n",
        "\n",
        "def train_ppo():\n",
        "    env = CarDealershipEnv()\n",
        "    model = PPO(\n",
        "        \"MlpPolicy\",\n",
        "        env,\n",
        "        learning_rate=3e-4,\n",
        "        batch_size=256,\n",
        "        n_steps=2048,\n",
        "        gamma=0.99,\n",
        "        gae_lambda=0.95,\n",
        "        clip_range=0.2,\n",
        "        ent_coef=0.01,\n",
        "        verbose=1,\n",
        "        tensorboard_log=\"./ppo_logs/\",\n",
        "    )\n",
        "\n",
        "    callback = EvalCallback(env, best_model_save_path=\"./ppo_best/\")\n",
        "    model.learn(total_timesteps=300_000, callback=callback)\n",
        "    model.save(\"car_ppo_agent\")\n",
        "    print(\"Training complete.\")\n",
        "    return model\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 8. RECOMMENDATION (ONE CAR)\n",
        "# ============================================================\n",
        "def query_model(model,\n",
        "                budget,\n",
        "                power_pref,\n",
        "                family_size,\n",
        "                body_pref,\n",
        "                fuel_pref,\n",
        "                body_strict=\"strong\",\n",
        "                fuel_strict=\"strong\",\n",
        "                budget_strict=\"strong\",\n",
        "                power_strict=\"soft\",\n",
        "                seats_strict=\"strong\"):\n",
        "\n",
        "    # Normalize budget into 0‚Äì1 space\n",
        "    max_price = df[\"price\"].max()\n",
        "    budget_norm = budget / max_price\n",
        "\n",
        "    # Normalize hp preference into 0‚Äì1\n",
        "    power_norm = power_pref  # already 0‚Äì1 suggested preference\n",
        "\n",
        "    # Build customer object\n",
        "    customer = {\n",
        "        \"budget\": budget_norm,\n",
        "        \"power_pref\": power_norm,\n",
        "        \"family_size\": family_size,\n",
        "        \"body_pref\": body_pref,\n",
        "        \"fuel_pref\": fuel_pref,\n",
        "        \"patience\": 4,\n",
        "        \"strictness\": {\n",
        "            \"body\": body_strict,\n",
        "            \"fuel\": fuel_strict,\n",
        "            \"budget\": budget_strict,\n",
        "            \"power\": power_strict,\n",
        "            \"seats\": seats_strict\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Create env and manually override\n",
        "    env = CarDealershipEnv()\n",
        "    env.customer = customer\n",
        "    env.max_score = max(match_score(customer, X[i], df.iloc[i]) for i in range(N_CARS))\n",
        "\n",
        "    print(\"\\nüßç Custom Customer:\", customer)\n",
        "    print(\"Max possible score:\", env.max_score)\n",
        "\n",
        "    # PPO prediction\n",
        "    obs = env._get_state()\n",
        "    ppo_action, _ = model.predict(obs, deterministic=True)\n",
        "    ppo_car = df.iloc[ppo_action]\n",
        "\n",
        "    print(\"\\nüî• PPO suggestion:\", ppo_car['brand'], ppo_car['model'])\n",
        "\n",
        "    # Refinement layer\n",
        "    top = refined_best_pick(customer, top=5)\n",
        "    best_idx, best_score = top[0]\n",
        "    best_car = df.iloc[best_idx]\n",
        "\n",
        "    print(\"\\nüîé Top 5 refined:\")\n",
        "    for idx, s in top:\n",
        "        c = df.iloc[idx]\n",
        "        print(c[\"brand\"], c[\"model\"], \"‚Äî score:\", s)\n",
        "\n",
        "    print(\"\\nüéØ FINAL RECOMMENDATION:\")\n",
        "    print(best_car[\"brand\"], best_car[\"model\"], \"‚Çπ\", best_car[\"price\"])\n",
        "\n",
        "    explain_recommendation(customer, best_car)\n",
        "\n",
        "def recommend_one_car(model=None):\n",
        "    if model is None:\n",
        "        model = PPO.load(\"car_ppo_agent\")\n",
        "\n",
        "    env = CarDealershipEnv()\n",
        "    obs, _ = env.reset()\n",
        "    customer = env.customer\n",
        "\n",
        "    print(\"\\nüßç Customer:\", customer)\n",
        "    print(\"Strictness:\", customer[\"strictness\"])\n",
        "    print(\"Max Score:\", env.max_score)\n",
        "\n",
        "    # PPO pick\n",
        "    ppo_action, _ = model.predict(obs, deterministic=True)\n",
        "    ppo_car = df.iloc[ppo_action]\n",
        "\n",
        "    print(\"\\nüî• PPO suggested:\", ppo_car[\"brand\"], ppo_car[\"model\"])\n",
        "\n",
        "    # Refinement layer\n",
        "    top = refined_best_pick(customer, top=5)\n",
        "    best_idx, best_score = top[0]\n",
        "    best_car = df.iloc[best_idx]\n",
        "\n",
        "    print(\"\\nüîé Top 5 refined:\")\n",
        "    for idx, score in top:\n",
        "        c = df.iloc[idx]\n",
        "        print(c[\"brand\"], c[\"model\"], \"‚Äî score:\", score)\n",
        "\n",
        "    print(\"\\nüéØ FINAL RECOMMENDATION:\")\n",
        "    print(best_car[\"brand\"], best_car[\"model\"], \"‚Çπ\", best_car[\"price\"])\n",
        "\n",
        "    explain_recommendation(customer, best_car)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# MAIN\n",
        "# ============================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model = train_ppo()\n",
        "    recommend_one_car(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ozMc6PxPAnG",
        "outputId": "1a22104f-d3a0-4adb-e380-ae44a5d14350",
        "collapsed": true
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Logging to ./ppo_logs/PPO_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 3.74     |\n",
            "|    ep_rew_mean     | -0.41    |\n",
            "| time/              |          |\n",
            "|    fps             | 187      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 10       |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 3.66        |\n",
            "|    ep_rew_mean          | 0.727       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 185         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 22          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014793703 |\n",
            "|    clip_fraction        | 0.095       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.84       |\n",
            "|    explained_variance   | -0.00375    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.63        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0245     |\n",
            "|    value_loss           | 13.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 3.54        |\n",
            "|    ep_rew_mean          | 1.71        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 187         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 32          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013550961 |\n",
            "|    clip_fraction        | 0.15        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.82       |\n",
            "|    explained_variance   | 0.0943      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.64        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0265     |\n",
            "|    value_loss           | 12.8        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 3.79        |\n",
            "|    ep_rew_mean          | -0.272      |\n",
            "| time/                   |             |\n",
            "|    fps                  | 187         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 43          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015902095 |\n",
            "|    clip_fraction        | 0.201       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.78       |\n",
            "|    explained_variance   | 0.164       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.91        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0313     |\n",
            "|    value_loss           | 11.8        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=2.74 +/- 5.58\n",
            "Episode length: 3.20 +/- 1.17\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 3.2        |\n",
            "|    mean_reward          | 2.74       |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 10000      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01630082 |\n",
            "|    clip_fraction        | 0.239      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -4.74      |\n",
            "|    explained_variance   | 0.199      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 5.7        |\n",
            "|    n_updates            | 40         |\n",
            "|    policy_gradient_loss | -0.0338    |\n",
            "|    value_loss           | 11         |\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/evaluation.py:70: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 3.55     |\n",
            "|    ep_rew_mean     | 1.94     |\n",
            "| time/              |          |\n",
            "|    fps             | 185      |\n",
            "|    iterations      | 5        |\n",
            "|    time_elapsed    | 55       |\n",
            "|    total_timesteps | 10240    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 3.73        |\n",
            "|    ep_rew_mean          | 0.534       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 185         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 66          |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015408639 |\n",
            "|    clip_fraction        | 0.186       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.71       |\n",
            "|    explained_variance   | 0.21        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.58        |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0282     |\n",
            "|    value_loss           | 11.8        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 3.52        |\n",
            "|    ep_rew_mean          | 2.13        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 184         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 77          |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014400659 |\n",
            "|    clip_fraction        | 0.203       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.64       |\n",
            "|    explained_variance   | 0.197       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.85        |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0298     |\n",
            "|    value_loss           | 11.8        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 3.57        |\n",
            "|    ep_rew_mean          | 1.36        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 183         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 89          |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014931209 |\n",
            "|    clip_fraction        | 0.195       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.59       |\n",
            "|    explained_variance   | 0.185       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.13        |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0301     |\n",
            "|    value_loss           | 13.1        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 3.59       |\n",
            "|    ep_rew_mean          | 1.98       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 183        |\n",
            "|    iterations           | 9          |\n",
            "|    time_elapsed         | 100        |\n",
            "|    total_timesteps      | 18432      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01506706 |\n",
            "|    clip_fraction        | 0.179      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -4.53      |\n",
            "|    explained_variance   | 0.206      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 6.3        |\n",
            "|    n_updates            | 80         |\n",
            "|    policy_gradient_loss | -0.0285    |\n",
            "|    value_loss           | 12.7       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=20000, episode_reward=2.59 +/- 5.67\n",
            "Episode length: 2.80 +/- 1.47\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 2.8         |\n",
            "|    mean_reward          | 2.59        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 20000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014827831 |\n",
            "|    clip_fraction        | 0.155       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.49       |\n",
            "|    explained_variance   | 0.127       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.8         |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.0288     |\n",
            "|    value_loss           | 13.1        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 3.59     |\n",
            "|    ep_rew_mean     | 2.54     |\n",
            "| time/              |          |\n",
            "|    fps             | 182      |\n",
            "|    iterations      | 10       |\n",
            "|    time_elapsed    | 112      |\n",
            "|    total_timesteps | 20480    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 3.66        |\n",
            "|    ep_rew_mean          | 1.94        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 182         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 123         |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013357423 |\n",
            "|    clip_fraction        | 0.141       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.46       |\n",
            "|    explained_variance   | 0.132       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.83        |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.0314     |\n",
            "|    value_loss           | 14.9        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 3.2          |\n",
            "|    ep_rew_mean          | 3.53         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 181          |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 135          |\n",
            "|    total_timesteps      | 24576        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0138996225 |\n",
            "|    clip_fraction        | 0.148        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.41        |\n",
            "|    explained_variance   | 0.16         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.66         |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.0321      |\n",
            "|    value_loss           | 13.2         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 3.47         |\n",
            "|    ep_rew_mean          | 2.93         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 181          |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 146          |\n",
            "|    total_timesteps      | 26624        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0137230735 |\n",
            "|    clip_fraction        | 0.152        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -4.34        |\n",
            "|    explained_variance   | 0.176        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.59         |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -0.033       |\n",
            "|    value_loss           | 14.1         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 3.32        |\n",
            "|    ep_rew_mean          | 3.37        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 180         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 158         |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012340464 |\n",
            "|    clip_fraction        | 0.137       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.26       |\n",
            "|    explained_variance   | 0.132       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.94        |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.0314     |\n",
            "|    value_loss           | 15.1        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=30000, episode_reward=5.75 +/- 4.46\n",
            "Episode length: 1.60 +/- 1.20\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1.6         |\n",
            "|    mean_reward          | 5.75        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 30000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013099728 |\n",
            "|    clip_fraction        | 0.142       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.15       |\n",
            "|    explained_variance   | 0.132       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.32        |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.031      |\n",
            "|    value_loss           | 14.5        |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 3.36     |\n",
            "|    ep_rew_mean     | 3.76     |\n",
            "| time/              |          |\n",
            "|    fps             | 180      |\n",
            "|    iterations      | 15       |\n",
            "|    time_elapsed    | 170      |\n",
            "|    total_timesteps | 30720    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 3.36        |\n",
            "|    ep_rew_mean          | 3.64        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 179         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 182         |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012658522 |\n",
            "|    clip_fraction        | 0.116       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.07       |\n",
            "|    explained_variance   | 0.109       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.28        |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.0284     |\n",
            "|    value_loss           | 17.3        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 3.38       |\n",
            "|    ep_rew_mean          | 4.08       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 179        |\n",
            "|    iterations           | 17         |\n",
            "|    time_elapsed         | 194        |\n",
            "|    total_timesteps      | 34816      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01207673 |\n",
            "|    clip_fraction        | 0.125      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.95      |\n",
            "|    explained_variance   | 0.141      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 8.68       |\n",
            "|    n_updates            | 160        |\n",
            "|    policy_gradient_loss | -0.0313    |\n",
            "|    value_loss           | 16.8       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 3.14        |\n",
            "|    ep_rew_mean          | 4.6         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 178         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 206         |\n",
            "|    total_timesteps      | 36864       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011364684 |\n",
            "|    clip_fraction        | 0.124       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.88       |\n",
            "|    explained_variance   | 0.157       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.51        |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.0303     |\n",
            "|    value_loss           | 16.6        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 3.2         |\n",
            "|    ep_rew_mean          | 4.59        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 177         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 219         |\n",
            "|    total_timesteps      | 38912       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013203124 |\n",
            "|    clip_fraction        | 0.15        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.76       |\n",
            "|    explained_variance   | 0.144       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.47        |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.033      |\n",
            "|    value_loss           | 17.1        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=40000, episode_reward=4.04 +/- 4.42\n",
            "Episode length: 2.80 +/- 1.47\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 2.8         |\n",
            "|    mean_reward          | 4.04        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 40000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012277074 |\n",
            "|    clip_fraction        | 0.136       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.65       |\n",
            "|    explained_variance   | 0.16        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.66        |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.0335     |\n",
            "|    value_loss           | 16.3        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 3.04     |\n",
            "|    ep_rew_mean     | 4.7      |\n",
            "| time/              |          |\n",
            "|    fps             | 176      |\n",
            "|    iterations      | 20       |\n",
            "|    time_elapsed    | 232      |\n",
            "|    total_timesteps | 40960    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.99        |\n",
            "|    ep_rew_mean          | 5.96        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 174         |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 246         |\n",
            "|    total_timesteps      | 43008       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011102354 |\n",
            "|    clip_fraction        | 0.0958      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.55       |\n",
            "|    explained_variance   | 0.163       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.49        |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.0291     |\n",
            "|    value_loss           | 17.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 3.12        |\n",
            "|    ep_rew_mean          | 6.05        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 173         |\n",
            "|    iterations           | 22          |\n",
            "|    time_elapsed         | 259         |\n",
            "|    total_timesteps      | 45056       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012403224 |\n",
            "|    clip_fraction        | 0.106       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.44       |\n",
            "|    explained_variance   | 0.192       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.27        |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.0303     |\n",
            "|    value_loss           | 16.6        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.85        |\n",
            "|    ep_rew_mean          | 5.4         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 173         |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 272         |\n",
            "|    total_timesteps      | 47104       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011143746 |\n",
            "|    clip_fraction        | 0.113       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.3        |\n",
            "|    explained_variance   | 0.184       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.77        |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | -0.0313     |\n",
            "|    value_loss           | 16.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.67        |\n",
            "|    ep_rew_mean          | 6.55        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 172         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 285         |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009961337 |\n",
            "|    clip_fraction        | 0.0978      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.21       |\n",
            "|    explained_variance   | 0.191       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.82        |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.0299     |\n",
            "|    value_loss           | 15.6        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=50000, episode_reward=5.99 +/- 4.10\n",
            "Episode length: 2.80 +/- 1.47\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 2.8         |\n",
            "|    mean_reward          | 5.99        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 50000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011758162 |\n",
            "|    clip_fraction        | 0.0804      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.14       |\n",
            "|    explained_variance   | 0.222       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.75        |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.0255     |\n",
            "|    value_loss           | 15.2        |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 2.43     |\n",
            "|    ep_rew_mean     | 6.98     |\n",
            "| time/              |          |\n",
            "|    fps             | 171      |\n",
            "|    iterations      | 25       |\n",
            "|    time_elapsed    | 299      |\n",
            "|    total_timesteps | 51200    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.68        |\n",
            "|    ep_rew_mean          | 6.79        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 170         |\n",
            "|    iterations           | 26          |\n",
            "|    time_elapsed         | 313         |\n",
            "|    total_timesteps      | 53248       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010062004 |\n",
            "|    clip_fraction        | 0.0916      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.01       |\n",
            "|    explained_variance   | 0.23        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.27        |\n",
            "|    n_updates            | 250         |\n",
            "|    policy_gradient_loss | -0.0278     |\n",
            "|    value_loss           | 14.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.73        |\n",
            "|    ep_rew_mean          | 7.4         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 168         |\n",
            "|    iterations           | 27          |\n",
            "|    time_elapsed         | 327         |\n",
            "|    total_timesteps      | 55296       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008820902 |\n",
            "|    clip_fraction        | 0.071       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.96       |\n",
            "|    explained_variance   | 0.226       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.88        |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | -0.0264     |\n",
            "|    value_loss           | 14.9        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.64        |\n",
            "|    ep_rew_mean          | 7.3         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 167         |\n",
            "|    iterations           | 28          |\n",
            "|    time_elapsed         | 342         |\n",
            "|    total_timesteps      | 57344       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009935548 |\n",
            "|    clip_fraction        | 0.0582      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.89       |\n",
            "|    explained_variance   | 0.218       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.47        |\n",
            "|    n_updates            | 270         |\n",
            "|    policy_gradient_loss | -0.0261     |\n",
            "|    value_loss           | 14.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.42        |\n",
            "|    ep_rew_mean          | 7.9         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 166         |\n",
            "|    iterations           | 29          |\n",
            "|    time_elapsed         | 357         |\n",
            "|    total_timesteps      | 59392       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009678315 |\n",
            "|    clip_fraction        | 0.101       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.84       |\n",
            "|    explained_variance   | 0.238       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.75        |\n",
            "|    n_updates            | 280         |\n",
            "|    policy_gradient_loss | -0.0276     |\n",
            "|    value_loss           | 14.3        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=60000, episode_reward=8.65 +/- 0.23\n",
            "Episode length: 1.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1           |\n",
            "|    mean_reward          | 8.65        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 60000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009239797 |\n",
            "|    clip_fraction        | 0.0887      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.79       |\n",
            "|    explained_variance   | 0.268       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.86        |\n",
            "|    n_updates            | 290         |\n",
            "|    policy_gradient_loss | -0.0244     |\n",
            "|    value_loss           | 13.3        |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 2.39     |\n",
            "|    ep_rew_mean     | 7.45     |\n",
            "| time/              |          |\n",
            "|    fps             | 164      |\n",
            "|    iterations      | 30       |\n",
            "|    time_elapsed    | 372      |\n",
            "|    total_timesteps | 61440    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.27        |\n",
            "|    ep_rew_mean          | 7.61        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 163         |\n",
            "|    iterations           | 31          |\n",
            "|    time_elapsed         | 388         |\n",
            "|    total_timesteps      | 63488       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009846203 |\n",
            "|    clip_fraction        | 0.0869      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.73       |\n",
            "|    explained_variance   | 0.284       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.59        |\n",
            "|    n_updates            | 300         |\n",
            "|    policy_gradient_loss | -0.0291     |\n",
            "|    value_loss           | 12.8        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.27        |\n",
            "|    ep_rew_mean          | 8.19        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 162         |\n",
            "|    iterations           | 32          |\n",
            "|    time_elapsed         | 403         |\n",
            "|    total_timesteps      | 65536       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010247269 |\n",
            "|    clip_fraction        | 0.106       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.67       |\n",
            "|    explained_variance   | 0.296       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.2         |\n",
            "|    n_updates            | 310         |\n",
            "|    policy_gradient_loss | -0.0288     |\n",
            "|    value_loss           | 12.2        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 2.35       |\n",
            "|    ep_rew_mean          | 7.7        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 161        |\n",
            "|    iterations           | 33         |\n",
            "|    time_elapsed         | 419        |\n",
            "|    total_timesteps      | 67584      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00879911 |\n",
            "|    clip_fraction        | 0.0631     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.58      |\n",
            "|    explained_variance   | 0.293      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 4.85       |\n",
            "|    n_updates            | 320        |\n",
            "|    policy_gradient_loss | -0.0235    |\n",
            "|    value_loss           | 11.9       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.45        |\n",
            "|    ep_rew_mean          | 7.56        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 160         |\n",
            "|    iterations           | 34          |\n",
            "|    time_elapsed         | 434         |\n",
            "|    total_timesteps      | 69632       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012132486 |\n",
            "|    clip_fraction        | 0.121       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.53       |\n",
            "|    explained_variance   | 0.239       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.55        |\n",
            "|    n_updates            | 330         |\n",
            "|    policy_gradient_loss | -0.0278     |\n",
            "|    value_loss           | 13.3        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=70000, episode_reward=8.73 +/- 0.28\n",
            "Episode length: 1.80 +/- 1.17\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 1.8          |\n",
            "|    mean_reward          | 8.73         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 70000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0101274485 |\n",
            "|    clip_fraction        | 0.0804       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.45        |\n",
            "|    explained_variance   | 0.319        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.61         |\n",
            "|    n_updates            | 340          |\n",
            "|    policy_gradient_loss | -0.0247      |\n",
            "|    value_loss           | 11.3         |\n",
            "------------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 2.39     |\n",
            "|    ep_rew_mean     | 7.56     |\n",
            "| time/              |          |\n",
            "|    fps             | 158      |\n",
            "|    iterations      | 35       |\n",
            "|    time_elapsed    | 450      |\n",
            "|    total_timesteps | 71680    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.26        |\n",
            "|    ep_rew_mean          | 8.05        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 157         |\n",
            "|    iterations           | 36          |\n",
            "|    time_elapsed         | 466         |\n",
            "|    total_timesteps      | 73728       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008020207 |\n",
            "|    clip_fraction        | 0.0678      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.42       |\n",
            "|    explained_variance   | 0.268       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.93        |\n",
            "|    n_updates            | 350         |\n",
            "|    policy_gradient_loss | -0.0234     |\n",
            "|    value_loss           | 11.9        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 2.29       |\n",
            "|    ep_rew_mean          | 7.99       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 156        |\n",
            "|    iterations           | 37         |\n",
            "|    time_elapsed         | 484        |\n",
            "|    total_timesteps      | 75776      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00942308 |\n",
            "|    clip_fraction        | 0.0811     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.33      |\n",
            "|    explained_variance   | 0.31       |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 5.62       |\n",
            "|    n_updates            | 360        |\n",
            "|    policy_gradient_loss | -0.0265    |\n",
            "|    value_loss           | 10.8       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.16        |\n",
            "|    ep_rew_mean          | 8.44        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 155         |\n",
            "|    iterations           | 38          |\n",
            "|    time_elapsed         | 500         |\n",
            "|    total_timesteps      | 77824       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008725578 |\n",
            "|    clip_fraction        | 0.0766      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.34       |\n",
            "|    explained_variance   | 0.305       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.59        |\n",
            "|    n_updates            | 370         |\n",
            "|    policy_gradient_loss | -0.0237     |\n",
            "|    value_loss           | 10.9        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.04        |\n",
            "|    ep_rew_mean          | 8.32        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 154         |\n",
            "|    iterations           | 39          |\n",
            "|    time_elapsed         | 517         |\n",
            "|    total_timesteps      | 79872       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009693579 |\n",
            "|    clip_fraction        | 0.0901      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.4        |\n",
            "|    explained_variance   | 0.303       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.23        |\n",
            "|    n_updates            | 380         |\n",
            "|    policy_gradient_loss | -0.0238     |\n",
            "|    value_loss           | 10.4        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=80000, episode_reward=8.85 +/- 1.75\n",
            "Episode length: 2.40 +/- 1.36\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 2.4         |\n",
            "|    mean_reward          | 8.85        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 80000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009194169 |\n",
            "|    clip_fraction        | 0.075       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.29       |\n",
            "|    explained_variance   | 0.344       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.47        |\n",
            "|    n_updates            | 390         |\n",
            "|    policy_gradient_loss | -0.0244     |\n",
            "|    value_loss           | 9.23        |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 2.32     |\n",
            "|    ep_rew_mean     | 8        |\n",
            "| time/              |          |\n",
            "|    fps             | 153      |\n",
            "|    iterations      | 40       |\n",
            "|    time_elapsed    | 534      |\n",
            "|    total_timesteps | 81920    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.12        |\n",
            "|    ep_rew_mean          | 8.09        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 152         |\n",
            "|    iterations           | 41          |\n",
            "|    time_elapsed         | 551         |\n",
            "|    total_timesteps      | 83968       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012057256 |\n",
            "|    clip_fraction        | 0.11        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.27       |\n",
            "|    explained_variance   | 0.343       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.8         |\n",
            "|    n_updates            | 400         |\n",
            "|    policy_gradient_loss | -0.0304     |\n",
            "|    value_loss           | 10          |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.14        |\n",
            "|    ep_rew_mean          | 8.54        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 151         |\n",
            "|    iterations           | 42          |\n",
            "|    time_elapsed         | 568         |\n",
            "|    total_timesteps      | 86016       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009330273 |\n",
            "|    clip_fraction        | 0.0771      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.22       |\n",
            "|    explained_variance   | 0.321       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.03        |\n",
            "|    n_updates            | 410         |\n",
            "|    policy_gradient_loss | -0.0224     |\n",
            "|    value_loss           | 9.39        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.95        |\n",
            "|    ep_rew_mean          | 8.36        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 150         |\n",
            "|    iterations           | 43          |\n",
            "|    time_elapsed         | 586         |\n",
            "|    total_timesteps      | 88064       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012901912 |\n",
            "|    clip_fraction        | 0.122       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.19       |\n",
            "|    explained_variance   | 0.329       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.12        |\n",
            "|    n_updates            | 420         |\n",
            "|    policy_gradient_loss | -0.0281     |\n",
            "|    value_loss           | 8.88        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=90000, episode_reward=8.84 +/- 0.55\n",
            "Episode length: 1.20 +/- 0.40\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1.2         |\n",
            "|    mean_reward          | 8.84        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 90000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010109637 |\n",
            "|    clip_fraction        | 0.0946      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.2        |\n",
            "|    explained_variance   | 0.285       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.68        |\n",
            "|    n_updates            | 430         |\n",
            "|    policy_gradient_loss | -0.025      |\n",
            "|    value_loss           | 9.62        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.98     |\n",
            "|    ep_rew_mean     | 8.45     |\n",
            "| time/              |          |\n",
            "|    fps             | 149      |\n",
            "|    iterations      | 44       |\n",
            "|    time_elapsed    | 604      |\n",
            "|    total_timesteps | 90112    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.19        |\n",
            "|    ep_rew_mean          | 8.12        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 147         |\n",
            "|    iterations           | 45          |\n",
            "|    time_elapsed         | 623         |\n",
            "|    total_timesteps      | 92160       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009188201 |\n",
            "|    clip_fraction        | 0.0775      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.15       |\n",
            "|    explained_variance   | 0.345       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.7         |\n",
            "|    n_updates            | 440         |\n",
            "|    policy_gradient_loss | -0.0216     |\n",
            "|    value_loss           | 7.65        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.09        |\n",
            "|    ep_rew_mean          | 8.62        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 146         |\n",
            "|    iterations           | 46          |\n",
            "|    time_elapsed         | 640         |\n",
            "|    total_timesteps      | 94208       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010758723 |\n",
            "|    clip_fraction        | 0.0948      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.18       |\n",
            "|    explained_variance   | 0.335       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.86        |\n",
            "|    n_updates            | 450         |\n",
            "|    policy_gradient_loss | -0.025      |\n",
            "|    value_loss           | 7.72        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.95        |\n",
            "|    ep_rew_mean          | 8.17        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 145         |\n",
            "|    iterations           | 47          |\n",
            "|    time_elapsed         | 659         |\n",
            "|    total_timesteps      | 96256       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009664737 |\n",
            "|    clip_fraction        | 0.0845      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.16       |\n",
            "|    explained_variance   | 0.282       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.49        |\n",
            "|    n_updates            | 460         |\n",
            "|    policy_gradient_loss | -0.0218     |\n",
            "|    value_loss           | 7.54        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.93        |\n",
            "|    ep_rew_mean          | 8.44        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 145         |\n",
            "|    iterations           | 48          |\n",
            "|    time_elapsed         | 677         |\n",
            "|    total_timesteps      | 98304       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011050219 |\n",
            "|    clip_fraction        | 0.109       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.16       |\n",
            "|    explained_variance   | 0.304       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.81        |\n",
            "|    n_updates            | 470         |\n",
            "|    policy_gradient_loss | -0.0258     |\n",
            "|    value_loss           | 8.28        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=100000, episode_reward=7.75 +/- 0.77\n",
            "Episode length: 1.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1           |\n",
            "|    mean_reward          | 7.75        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 100000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009974543 |\n",
            "|    clip_fraction        | 0.0885      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.15       |\n",
            "|    explained_variance   | 0.3         |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.91        |\n",
            "|    n_updates            | 480         |\n",
            "|    policy_gradient_loss | -0.0224     |\n",
            "|    value_loss           | 7.46        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 2.03     |\n",
            "|    ep_rew_mean     | 8.66     |\n",
            "| time/              |          |\n",
            "|    fps             | 144      |\n",
            "|    iterations      | 49       |\n",
            "|    time_elapsed    | 696      |\n",
            "|    total_timesteps | 100352   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.83        |\n",
            "|    ep_rew_mean          | 8.56        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 143         |\n",
            "|    iterations           | 50          |\n",
            "|    time_elapsed         | 714         |\n",
            "|    total_timesteps      | 102400      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010954685 |\n",
            "|    clip_fraction        | 0.101       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.19       |\n",
            "|    explained_variance   | 0.272       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.47        |\n",
            "|    n_updates            | 490         |\n",
            "|    policy_gradient_loss | -0.025      |\n",
            "|    value_loss           | 7.91        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.03        |\n",
            "|    ep_rew_mean          | 8.7         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 142         |\n",
            "|    iterations           | 51          |\n",
            "|    time_elapsed         | 732         |\n",
            "|    total_timesteps      | 104448      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008648933 |\n",
            "|    clip_fraction        | 0.0725      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.17       |\n",
            "|    explained_variance   | 0.319       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.75        |\n",
            "|    n_updates            | 500         |\n",
            "|    policy_gradient_loss | -0.0217     |\n",
            "|    value_loss           | 7.4         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.17        |\n",
            "|    ep_rew_mean          | 8.95        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 141         |\n",
            "|    iterations           | 52          |\n",
            "|    time_elapsed         | 750         |\n",
            "|    total_timesteps      | 106496      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011246797 |\n",
            "|    clip_fraction        | 0.11        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.17       |\n",
            "|    explained_variance   | 0.322       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.41        |\n",
            "|    n_updates            | 510         |\n",
            "|    policy_gradient_loss | -0.0247     |\n",
            "|    value_loss           | 8.13        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.08        |\n",
            "|    ep_rew_mean          | 8.99        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 141         |\n",
            "|    iterations           | 53          |\n",
            "|    time_elapsed         | 768         |\n",
            "|    total_timesteps      | 108544      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010452635 |\n",
            "|    clip_fraction        | 0.0924      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.25       |\n",
            "|    explained_variance   | 0.272       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.02        |\n",
            "|    n_updates            | 520         |\n",
            "|    policy_gradient_loss | -0.0231     |\n",
            "|    value_loss           | 8.27        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=110000, episode_reward=10.31 +/- 2.66\n",
            "Episode length: 2.20 +/- 1.17\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 2.2         |\n",
            "|    mean_reward          | 10.3        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 110000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011404998 |\n",
            "|    clip_fraction        | 0.108       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.18       |\n",
            "|    explained_variance   | 0.317       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.43        |\n",
            "|    n_updates            | 530         |\n",
            "|    policy_gradient_loss | -0.0257     |\n",
            "|    value_loss           | 7.7         |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 2        |\n",
            "|    ep_rew_mean     | 8.78     |\n",
            "| time/              |          |\n",
            "|    fps             | 140      |\n",
            "|    iterations      | 54       |\n",
            "|    time_elapsed    | 786      |\n",
            "|    total_timesteps | 110592   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.99        |\n",
            "|    ep_rew_mean          | 8.52        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 140         |\n",
            "|    iterations           | 55          |\n",
            "|    time_elapsed         | 804         |\n",
            "|    total_timesteps      | 112640      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010543809 |\n",
            "|    clip_fraction        | 0.0979      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.23       |\n",
            "|    explained_variance   | 0.294       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.44        |\n",
            "|    n_updates            | 540         |\n",
            "|    policy_gradient_loss | -0.0255     |\n",
            "|    value_loss           | 7.62        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.97        |\n",
            "|    ep_rew_mean          | 8.53        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 139         |\n",
            "|    iterations           | 56          |\n",
            "|    time_elapsed         | 823         |\n",
            "|    total_timesteps      | 114688      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011321219 |\n",
            "|    clip_fraction        | 0.0891      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.19       |\n",
            "|    explained_variance   | 0.33        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.71        |\n",
            "|    n_updates            | 550         |\n",
            "|    policy_gradient_loss | -0.0242     |\n",
            "|    value_loss           | 7.3         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.88        |\n",
            "|    ep_rew_mean          | 8.8         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 138         |\n",
            "|    iterations           | 57          |\n",
            "|    time_elapsed         | 840         |\n",
            "|    total_timesteps      | 116736      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012816733 |\n",
            "|    clip_fraction        | 0.129       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.21       |\n",
            "|    explained_variance   | 0.296       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.99        |\n",
            "|    n_updates            | 560         |\n",
            "|    policy_gradient_loss | -0.0254     |\n",
            "|    value_loss           | 6.67        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.06        |\n",
            "|    ep_rew_mean          | 8.74        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 138         |\n",
            "|    iterations           | 58          |\n",
            "|    time_elapsed         | 859         |\n",
            "|    total_timesteps      | 118784      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009598232 |\n",
            "|    clip_fraction        | 0.11        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.2        |\n",
            "|    explained_variance   | 0.288       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.5         |\n",
            "|    n_updates            | 570         |\n",
            "|    policy_gradient_loss | -0.0257     |\n",
            "|    value_loss           | 7.53        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=120000, episode_reward=8.83 +/- 0.08\n",
            "Episode length: 1.20 +/- 0.40\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1.2         |\n",
            "|    mean_reward          | 8.83        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 120000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011374262 |\n",
            "|    clip_fraction        | 0.108       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.24       |\n",
            "|    explained_variance   | 0.268       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.53        |\n",
            "|    n_updates            | 580         |\n",
            "|    policy_gradient_loss | -0.0261     |\n",
            "|    value_loss           | 7.54        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 2.06     |\n",
            "|    ep_rew_mean     | 8.69     |\n",
            "| time/              |          |\n",
            "|    fps             | 137      |\n",
            "|    iterations      | 59       |\n",
            "|    time_elapsed    | 876      |\n",
            "|    total_timesteps | 120832   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.07        |\n",
            "|    ep_rew_mean          | 8.92        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 137         |\n",
            "|    iterations           | 60          |\n",
            "|    time_elapsed         | 894         |\n",
            "|    total_timesteps      | 122880      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011577729 |\n",
            "|    clip_fraction        | 0.117       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.24       |\n",
            "|    explained_variance   | 0.275       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.63        |\n",
            "|    n_updates            | 590         |\n",
            "|    policy_gradient_loss | -0.0269     |\n",
            "|    value_loss           | 7.39        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.02        |\n",
            "|    ep_rew_mean          | 9           |\n",
            "| time/                   |             |\n",
            "|    fps                  | 137         |\n",
            "|    iterations           | 61          |\n",
            "|    time_elapsed         | 911         |\n",
            "|    total_timesteps      | 124928      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011879971 |\n",
            "|    clip_fraction        | 0.128       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.25       |\n",
            "|    explained_variance   | 0.262       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.72        |\n",
            "|    n_updates            | 600         |\n",
            "|    policy_gradient_loss | -0.0257     |\n",
            "|    value_loss           | 7.14        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 2.15       |\n",
            "|    ep_rew_mean          | 9.03       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 136        |\n",
            "|    iterations           | 62         |\n",
            "|    time_elapsed         | 929        |\n",
            "|    total_timesteps      | 126976     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01178612 |\n",
            "|    clip_fraction        | 0.111      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.28      |\n",
            "|    explained_variance   | 0.26       |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 3.9        |\n",
            "|    n_updates            | 610        |\n",
            "|    policy_gradient_loss | -0.029     |\n",
            "|    value_loss           | 7.95       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.88        |\n",
            "|    ep_rew_mean          | 8.69        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 136         |\n",
            "|    iterations           | 63          |\n",
            "|    time_elapsed         | 947         |\n",
            "|    total_timesteps      | 129024      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013142955 |\n",
            "|    clip_fraction        | 0.13        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.18       |\n",
            "|    explained_variance   | 0.292       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.31        |\n",
            "|    n_updates            | 620         |\n",
            "|    policy_gradient_loss | -0.0289     |\n",
            "|    value_loss           | 6.59        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=130000, episode_reward=9.01 +/- 0.60\n",
            "Episode length: 1.20 +/- 0.40\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 1.2          |\n",
            "|    mean_reward          | 9.01         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 130000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0110243345 |\n",
            "|    clip_fraction        | 0.115        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.2         |\n",
            "|    explained_variance   | 0.291        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.57         |\n",
            "|    n_updates            | 630          |\n",
            "|    policy_gradient_loss | -0.0267      |\n",
            "|    value_loss           | 7.25         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.9      |\n",
            "|    ep_rew_mean     | 8.94     |\n",
            "| time/              |          |\n",
            "|    fps             | 135      |\n",
            "|    iterations      | 64       |\n",
            "|    time_elapsed    | 965      |\n",
            "|    total_timesteps | 131072   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.05        |\n",
            "|    ep_rew_mean          | 9.14        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 135         |\n",
            "|    iterations           | 65          |\n",
            "|    time_elapsed         | 983         |\n",
            "|    total_timesteps      | 133120      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009808075 |\n",
            "|    clip_fraction        | 0.116       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.24       |\n",
            "|    explained_variance   | 0.278       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.26        |\n",
            "|    n_updates            | 640         |\n",
            "|    policy_gradient_loss | -0.0257     |\n",
            "|    value_loss           | 6.89        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.27        |\n",
            "|    ep_rew_mean          | 9.03        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 135         |\n",
            "|    iterations           | 66          |\n",
            "|    time_elapsed         | 999         |\n",
            "|    total_timesteps      | 135168      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011598657 |\n",
            "|    clip_fraction        | 0.132       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.2        |\n",
            "|    explained_variance   | 0.264       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.96        |\n",
            "|    n_updates            | 650         |\n",
            "|    policy_gradient_loss | -0.0282     |\n",
            "|    value_loss           | 7.61        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.96        |\n",
            "|    ep_rew_mean          | 8.84        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 134         |\n",
            "|    iterations           | 67          |\n",
            "|    time_elapsed         | 1016        |\n",
            "|    total_timesteps      | 137216      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012029409 |\n",
            "|    clip_fraction        | 0.127       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.17       |\n",
            "|    explained_variance   | 0.251       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.19        |\n",
            "|    n_updates            | 660         |\n",
            "|    policy_gradient_loss | -0.0263     |\n",
            "|    value_loss           | 7.81        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.13        |\n",
            "|    ep_rew_mean          | 8.61        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 134         |\n",
            "|    iterations           | 68          |\n",
            "|    time_elapsed         | 1034        |\n",
            "|    total_timesteps      | 139264      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010992512 |\n",
            "|    clip_fraction        | 0.124       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.22       |\n",
            "|    explained_variance   | 0.243       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.09        |\n",
            "|    n_updates            | 670         |\n",
            "|    policy_gradient_loss | -0.0269     |\n",
            "|    value_loss           | 7           |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=140000, episode_reward=8.85 +/- 0.06\n",
            "Episode length: 1.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1           |\n",
            "|    mean_reward          | 8.85        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 140000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013735939 |\n",
            "|    clip_fraction        | 0.134       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.09       |\n",
            "|    explained_variance   | 0.243       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.69        |\n",
            "|    n_updates            | 680         |\n",
            "|    policy_gradient_loss | -0.0272     |\n",
            "|    value_loss           | 7.36        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.98     |\n",
            "|    ep_rew_mean     | 8.91     |\n",
            "| time/              |          |\n",
            "|    fps             | 134      |\n",
            "|    iterations      | 69       |\n",
            "|    time_elapsed    | 1051     |\n",
            "|    total_timesteps | 141312   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 1.97        |\n",
            "|    ep_rew_mean          | 9.34        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 134         |\n",
            "|    iterations           | 70          |\n",
            "|    time_elapsed         | 1069        |\n",
            "|    total_timesteps      | 143360      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011611127 |\n",
            "|    clip_fraction        | 0.12        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.19       |\n",
            "|    explained_variance   | 0.249       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.95        |\n",
            "|    n_updates            | 690         |\n",
            "|    policy_gradient_loss | -0.0258     |\n",
            "|    value_loss           | 6.52        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.1         |\n",
            "|    ep_rew_mean          | 9.31        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 133         |\n",
            "|    iterations           | 71          |\n",
            "|    time_elapsed         | 1085        |\n",
            "|    total_timesteps      | 145408      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012939277 |\n",
            "|    clip_fraction        | 0.129       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.2        |\n",
            "|    explained_variance   | 0.256       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.79        |\n",
            "|    n_updates            | 700         |\n",
            "|    policy_gradient_loss | -0.0311     |\n",
            "|    value_loss           | 7.39        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.25        |\n",
            "|    ep_rew_mean          | 9.31        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 133         |\n",
            "|    iterations           | 72          |\n",
            "|    time_elapsed         | 1102        |\n",
            "|    total_timesteps      | 147456      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012046552 |\n",
            "|    clip_fraction        | 0.138       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.12       |\n",
            "|    explained_variance   | 0.263       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.83        |\n",
            "|    n_updates            | 710         |\n",
            "|    policy_gradient_loss | -0.0265     |\n",
            "|    value_loss           | 7.7         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.11        |\n",
            "|    ep_rew_mean          | 9.11        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 133         |\n",
            "|    iterations           | 73          |\n",
            "|    time_elapsed         | 1119        |\n",
            "|    total_timesteps      | 149504      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011167118 |\n",
            "|    clip_fraction        | 0.108       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.12       |\n",
            "|    explained_variance   | 0.275       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.76        |\n",
            "|    n_updates            | 720         |\n",
            "|    policy_gradient_loss | -0.024      |\n",
            "|    value_loss           | 7.07        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=150000, episode_reward=8.58 +/- 0.56\n",
            "Episode length: 1.60 +/- 0.80\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1.6        |\n",
            "|    mean_reward          | 8.58       |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 150000     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01184712 |\n",
            "|    clip_fraction        | 0.128      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.09      |\n",
            "|    explained_variance   | 0.281      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 3.77       |\n",
            "|    n_updates            | 730        |\n",
            "|    policy_gradient_loss | -0.0273    |\n",
            "|    value_loss           | 7.01       |\n",
            "----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 2.4      |\n",
            "|    ep_rew_mean     | 8.85     |\n",
            "| time/              |          |\n",
            "|    fps             | 133      |\n",
            "|    iterations      | 74       |\n",
            "|    time_elapsed    | 1136     |\n",
            "|    total_timesteps | 151552   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.04        |\n",
            "|    ep_rew_mean          | 8.99        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 133         |\n",
            "|    iterations           | 75          |\n",
            "|    time_elapsed         | 1152        |\n",
            "|    total_timesteps      | 153600      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011737623 |\n",
            "|    clip_fraction        | 0.129       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.14       |\n",
            "|    explained_variance   | 0.278       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.06        |\n",
            "|    n_updates            | 740         |\n",
            "|    policy_gradient_loss | -0.0276     |\n",
            "|    value_loss           | 6.69        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.12        |\n",
            "|    ep_rew_mean          | 9.05        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 133         |\n",
            "|    iterations           | 76          |\n",
            "|    time_elapsed         | 1169        |\n",
            "|    total_timesteps      | 155648      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012167506 |\n",
            "|    clip_fraction        | 0.124       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.13       |\n",
            "|    explained_variance   | 0.301       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.82        |\n",
            "|    n_updates            | 750         |\n",
            "|    policy_gradient_loss | -0.0297     |\n",
            "|    value_loss           | 7.22        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.3          |\n",
            "|    ep_rew_mean          | 9.25         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 132          |\n",
            "|    iterations           | 77           |\n",
            "|    time_elapsed         | 1185         |\n",
            "|    total_timesteps      | 157696       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0116854515 |\n",
            "|    clip_fraction        | 0.108        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.1         |\n",
            "|    explained_variance   | 0.181        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.74         |\n",
            "|    n_updates            | 760          |\n",
            "|    policy_gradient_loss | -0.0246      |\n",
            "|    value_loss           | 6.99         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.27        |\n",
            "|    ep_rew_mean          | 9.29        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 132         |\n",
            "|    iterations           | 78          |\n",
            "|    time_elapsed         | 1201        |\n",
            "|    total_timesteps      | 159744      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010342548 |\n",
            "|    clip_fraction        | 0.103       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.08       |\n",
            "|    explained_variance   | 0.247       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.09        |\n",
            "|    n_updates            | 770         |\n",
            "|    policy_gradient_loss | -0.025      |\n",
            "|    value_loss           | 7.14        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=160000, episode_reward=9.34 +/- 2.21\n",
            "Episode length: 2.60 +/- 1.02\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 2.6          |\n",
            "|    mean_reward          | 9.34         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 160000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0106068645 |\n",
            "|    clip_fraction        | 0.113        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.05        |\n",
            "|    explained_variance   | 0.268        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.96         |\n",
            "|    n_updates            | 780          |\n",
            "|    policy_gradient_loss | -0.0253      |\n",
            "|    value_loss           | 6.24         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 2.13     |\n",
            "|    ep_rew_mean     | 9.18     |\n",
            "| time/              |          |\n",
            "|    fps             | 132      |\n",
            "|    iterations      | 79       |\n",
            "|    time_elapsed    | 1218     |\n",
            "|    total_timesteps | 161792   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.25        |\n",
            "|    ep_rew_mean          | 9.5         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 132         |\n",
            "|    iterations           | 80          |\n",
            "|    time_elapsed         | 1234        |\n",
            "|    total_timesteps      | 163840      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012600592 |\n",
            "|    clip_fraction        | 0.126       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.08       |\n",
            "|    explained_variance   | 0.223       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.83        |\n",
            "|    n_updates            | 790         |\n",
            "|    policy_gradient_loss | -0.0256     |\n",
            "|    value_loss           | 5.93        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.4         |\n",
            "|    ep_rew_mean          | 9.7         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 132         |\n",
            "|    iterations           | 81          |\n",
            "|    time_elapsed         | 1250        |\n",
            "|    total_timesteps      | 165888      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010309734 |\n",
            "|    clip_fraction        | 0.109       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.06       |\n",
            "|    explained_variance   | 0.238       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.94        |\n",
            "|    n_updates            | 800         |\n",
            "|    policy_gradient_loss | -0.0237     |\n",
            "|    value_loss           | 6.82        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 2.07       |\n",
            "|    ep_rew_mean          | 9.24       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 132        |\n",
            "|    iterations           | 82         |\n",
            "|    time_elapsed         | 1265       |\n",
            "|    total_timesteps      | 167936     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01166385 |\n",
            "|    clip_fraction        | 0.163      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.04      |\n",
            "|    explained_variance   | 0.217      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 3.29       |\n",
            "|    n_updates            | 810        |\n",
            "|    policy_gradient_loss | -0.0297    |\n",
            "|    value_loss           | 7.17       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.37        |\n",
            "|    ep_rew_mean          | 9.51        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 132         |\n",
            "|    iterations           | 83          |\n",
            "|    time_elapsed         | 1281        |\n",
            "|    total_timesteps      | 169984      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011140773 |\n",
            "|    clip_fraction        | 0.119       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.02       |\n",
            "|    explained_variance   | 0.189       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.78        |\n",
            "|    n_updates            | 820         |\n",
            "|    policy_gradient_loss | -0.0249     |\n",
            "|    value_loss           | 7.07        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=170000, episode_reward=9.80 +/- 1.36\n",
            "Episode length: 2.00 +/- 0.89\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 2           |\n",
            "|    mean_reward          | 9.8         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 170000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010582289 |\n",
            "|    clip_fraction        | 0.133       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.01       |\n",
            "|    explained_variance   | 0.238       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.94        |\n",
            "|    n_updates            | 830         |\n",
            "|    policy_gradient_loss | -0.0287     |\n",
            "|    value_loss           | 6.58        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 2.47     |\n",
            "|    ep_rew_mean     | 9.66     |\n",
            "| time/              |          |\n",
            "|    fps             | 132      |\n",
            "|    iterations      | 84       |\n",
            "|    time_elapsed    | 1296     |\n",
            "|    total_timesteps | 172032   |\n",
            "---------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 2.39      |\n",
            "|    ep_rew_mean          | 9.78      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 132       |\n",
            "|    iterations           | 85        |\n",
            "|    time_elapsed         | 1312      |\n",
            "|    total_timesteps      | 174080    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0128923 |\n",
            "|    clip_fraction        | 0.14      |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.92     |\n",
            "|    explained_variance   | 0.244     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 3.39      |\n",
            "|    n_updates            | 840       |\n",
            "|    policy_gradient_loss | -0.0276   |\n",
            "|    value_loss           | 7.25      |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.62        |\n",
            "|    ep_rew_mean          | 9.67        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 132         |\n",
            "|    iterations           | 86          |\n",
            "|    time_elapsed         | 1327        |\n",
            "|    total_timesteps      | 176128      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012665116 |\n",
            "|    clip_fraction        | 0.135       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2          |\n",
            "|    explained_variance   | 0.211       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.88        |\n",
            "|    n_updates            | 850         |\n",
            "|    policy_gradient_loss | -0.0257     |\n",
            "|    value_loss           | 6.11        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.32        |\n",
            "|    ep_rew_mean          | 9.9         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 132         |\n",
            "|    iterations           | 87          |\n",
            "|    time_elapsed         | 1343        |\n",
            "|    total_timesteps      | 178176      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011113551 |\n",
            "|    clip_fraction        | 0.12        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.94       |\n",
            "|    explained_variance   | 0.262       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.15        |\n",
            "|    n_updates            | 860         |\n",
            "|    policy_gradient_loss | -0.0263     |\n",
            "|    value_loss           | 6.72        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=180000, episode_reward=11.96 +/- 1.90\n",
            "Episode length: 2.80 +/- 0.98\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 2.8         |\n",
            "|    mean_reward          | 12          |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 180000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010243222 |\n",
            "|    clip_fraction        | 0.104       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.95       |\n",
            "|    explained_variance   | 0.23        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.19        |\n",
            "|    n_updates            | 870         |\n",
            "|    policy_gradient_loss | -0.0229     |\n",
            "|    value_loss           | 6.54        |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 2.24     |\n",
            "|    ep_rew_mean     | 9.24     |\n",
            "| time/              |          |\n",
            "|    fps             | 132      |\n",
            "|    iterations      | 88       |\n",
            "|    time_elapsed    | 1359     |\n",
            "|    total_timesteps | 180224   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.71        |\n",
            "|    ep_rew_mean          | 9.18        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 132         |\n",
            "|    iterations           | 89          |\n",
            "|    time_elapsed         | 1373        |\n",
            "|    total_timesteps      | 182272      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010255473 |\n",
            "|    clip_fraction        | 0.108       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.87       |\n",
            "|    explained_variance   | 0.205       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.07        |\n",
            "|    n_updates            | 880         |\n",
            "|    policy_gradient_loss | -0.0221     |\n",
            "|    value_loss           | 7.25        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.38        |\n",
            "|    ep_rew_mean          | 9.83        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 132         |\n",
            "|    iterations           | 90          |\n",
            "|    time_elapsed         | 1388        |\n",
            "|    total_timesteps      | 184320      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010193065 |\n",
            "|    clip_fraction        | 0.133       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.89       |\n",
            "|    explained_variance   | 0.222       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.32        |\n",
            "|    n_updates            | 890         |\n",
            "|    policy_gradient_loss | -0.0277     |\n",
            "|    value_loss           | 8.52        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.49        |\n",
            "|    ep_rew_mean          | 9.42        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 132         |\n",
            "|    iterations           | 91          |\n",
            "|    time_elapsed         | 1403        |\n",
            "|    total_timesteps      | 186368      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009815912 |\n",
            "|    clip_fraction        | 0.0935      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.87       |\n",
            "|    explained_variance   | 0.211       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.53        |\n",
            "|    n_updates            | 900         |\n",
            "|    policy_gradient_loss | -0.0199     |\n",
            "|    value_loss           | 6.68        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.48        |\n",
            "|    ep_rew_mean          | 10.2        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 132         |\n",
            "|    iterations           | 92          |\n",
            "|    time_elapsed         | 1418        |\n",
            "|    total_timesteps      | 188416      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011084534 |\n",
            "|    clip_fraction        | 0.12        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.9        |\n",
            "|    explained_variance   | 0.247       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.24        |\n",
            "|    n_updates            | 910         |\n",
            "|    policy_gradient_loss | -0.0237     |\n",
            "|    value_loss           | 6.78        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=190000, episode_reward=10.18 +/- 1.96\n",
            "Episode length: 2.60 +/- 1.02\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 2.6         |\n",
            "|    mean_reward          | 10.2        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 190000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011826398 |\n",
            "|    clip_fraction        | 0.131       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.82       |\n",
            "|    explained_variance   | 0.178       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.41        |\n",
            "|    n_updates            | 920         |\n",
            "|    policy_gradient_loss | -0.0246     |\n",
            "|    value_loss           | 6.81        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 2.49     |\n",
            "|    ep_rew_mean     | 9.8      |\n",
            "| time/              |          |\n",
            "|    fps             | 132      |\n",
            "|    iterations      | 93       |\n",
            "|    time_elapsed    | 1433     |\n",
            "|    total_timesteps | 190464   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.59        |\n",
            "|    ep_rew_mean          | 9.83        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 132         |\n",
            "|    iterations           | 94          |\n",
            "|    time_elapsed         | 1447        |\n",
            "|    total_timesteps      | 192512      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009195822 |\n",
            "|    clip_fraction        | 0.0979      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.83       |\n",
            "|    explained_variance   | 0.214       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.19        |\n",
            "|    n_updates            | 930         |\n",
            "|    policy_gradient_loss | -0.024      |\n",
            "|    value_loss           | 6.82        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.71        |\n",
            "|    ep_rew_mean          | 10.2        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 133         |\n",
            "|    iterations           | 95          |\n",
            "|    time_elapsed         | 1462        |\n",
            "|    total_timesteps      | 194560      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010590082 |\n",
            "|    clip_fraction        | 0.102       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.81       |\n",
            "|    explained_variance   | 0.19        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.36        |\n",
            "|    n_updates            | 940         |\n",
            "|    policy_gradient_loss | -0.024      |\n",
            "|    value_loss           | 7.38        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.46        |\n",
            "|    ep_rew_mean          | 9.57        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 133         |\n",
            "|    iterations           | 96          |\n",
            "|    time_elapsed         | 1476        |\n",
            "|    total_timesteps      | 196608      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009312018 |\n",
            "|    clip_fraction        | 0.0921      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.75       |\n",
            "|    explained_variance   | 0.247       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.4         |\n",
            "|    n_updates            | 950         |\n",
            "|    policy_gradient_loss | -0.0208     |\n",
            "|    value_loss           | 6.86        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 2.75       |\n",
            "|    ep_rew_mean          | 9.57       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 133        |\n",
            "|    iterations           | 97         |\n",
            "|    time_elapsed         | 1490       |\n",
            "|    total_timesteps      | 198656     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00996645 |\n",
            "|    clip_fraction        | 0.0865     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.73      |\n",
            "|    explained_variance   | 0.203      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 3.67       |\n",
            "|    n_updates            | 960        |\n",
            "|    policy_gradient_loss | -0.0223    |\n",
            "|    value_loss           | 7.48       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=200000, episode_reward=10.57 +/- 2.08\n",
            "Episode length: 2.40 +/- 0.80\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 2.4          |\n",
            "|    mean_reward          | 10.6         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 200000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0105242655 |\n",
            "|    clip_fraction        | 0.0981       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.74        |\n",
            "|    explained_variance   | 0.212        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.85         |\n",
            "|    n_updates            | 970          |\n",
            "|    policy_gradient_loss | -0.022       |\n",
            "|    value_loss           | 6.88         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 2.74     |\n",
            "|    ep_rew_mean     | 9.71     |\n",
            "| time/              |          |\n",
            "|    fps             | 133      |\n",
            "|    iterations      | 98       |\n",
            "|    time_elapsed    | 1505     |\n",
            "|    total_timesteps | 200704   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.63        |\n",
            "|    ep_rew_mean          | 10.1        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 133         |\n",
            "|    iterations           | 99          |\n",
            "|    time_elapsed         | 1519        |\n",
            "|    total_timesteps      | 202752      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011469422 |\n",
            "|    clip_fraction        | 0.13        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.74       |\n",
            "|    explained_variance   | 0.185       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.13        |\n",
            "|    n_updates            | 980         |\n",
            "|    policy_gradient_loss | -0.0259     |\n",
            "|    value_loss           | 6.69        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.53        |\n",
            "|    ep_rew_mean          | 9.87        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 133         |\n",
            "|    iterations           | 100         |\n",
            "|    time_elapsed         | 1533        |\n",
            "|    total_timesteps      | 204800      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009834096 |\n",
            "|    clip_fraction        | 0.111       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.74       |\n",
            "|    explained_variance   | 0.22        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.37        |\n",
            "|    n_updates            | 990         |\n",
            "|    policy_gradient_loss | -0.0245     |\n",
            "|    value_loss           | 6.16        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.86        |\n",
            "|    ep_rew_mean          | 10.2        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 133         |\n",
            "|    iterations           | 101         |\n",
            "|    time_elapsed         | 1547        |\n",
            "|    total_timesteps      | 206848      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008549371 |\n",
            "|    clip_fraction        | 0.0752      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.73       |\n",
            "|    explained_variance   | 0.195       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.44        |\n",
            "|    n_updates            | 1000        |\n",
            "|    policy_gradient_loss | -0.0195     |\n",
            "|    value_loss           | 7.51        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.71        |\n",
            "|    ep_rew_mean          | 9.86        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 133         |\n",
            "|    iterations           | 102         |\n",
            "|    time_elapsed         | 1560        |\n",
            "|    total_timesteps      | 208896      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009842274 |\n",
            "|    clip_fraction        | 0.0897      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.73       |\n",
            "|    explained_variance   | 0.205       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.45        |\n",
            "|    n_updates            | 1010        |\n",
            "|    policy_gradient_loss | -0.0224     |\n",
            "|    value_loss           | 6.18        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=210000, episode_reward=10.13 +/- 1.06\n",
            "Episode length: 2.20 +/- 0.98\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 2.2         |\n",
            "|    mean_reward          | 10.1        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 210000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009414099 |\n",
            "|    clip_fraction        | 0.0863      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.72       |\n",
            "|    explained_variance   | 0.175       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.35        |\n",
            "|    n_updates            | 1020        |\n",
            "|    policy_gradient_loss | -0.0225     |\n",
            "|    value_loss           | 6.55        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 2.65     |\n",
            "|    ep_rew_mean     | 10.4     |\n",
            "| time/              |          |\n",
            "|    fps             | 133      |\n",
            "|    iterations      | 103      |\n",
            "|    time_elapsed    | 1574     |\n",
            "|    total_timesteps | 210944   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.89        |\n",
            "|    ep_rew_mean          | 10.1        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 134         |\n",
            "|    iterations           | 104         |\n",
            "|    time_elapsed         | 1588        |\n",
            "|    total_timesteps      | 212992      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009535512 |\n",
            "|    clip_fraction        | 0.0974      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.71       |\n",
            "|    explained_variance   | 0.205       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.96        |\n",
            "|    n_updates            | 1030        |\n",
            "|    policy_gradient_loss | -0.0223     |\n",
            "|    value_loss           | 5.95        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.82        |\n",
            "|    ep_rew_mean          | 9.63        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 134         |\n",
            "|    iterations           | 105         |\n",
            "|    time_elapsed         | 1602        |\n",
            "|    total_timesteps      | 215040      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009523688 |\n",
            "|    clip_fraction        | 0.0894      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.75       |\n",
            "|    explained_variance   | 0.205       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4           |\n",
            "|    n_updates            | 1040        |\n",
            "|    policy_gradient_loss | -0.0223     |\n",
            "|    value_loss           | 7.25        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.9         |\n",
            "|    ep_rew_mean          | 9.74        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 134         |\n",
            "|    iterations           | 106         |\n",
            "|    time_elapsed         | 1616        |\n",
            "|    total_timesteps      | 217088      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008800272 |\n",
            "|    clip_fraction        | 0.0939      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.76       |\n",
            "|    explained_variance   | 0.217       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.41        |\n",
            "|    n_updates            | 1050        |\n",
            "|    policy_gradient_loss | -0.023      |\n",
            "|    value_loss           | 6.37        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.9         |\n",
            "|    ep_rew_mean          | 10.1        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 134         |\n",
            "|    iterations           | 107         |\n",
            "|    time_elapsed         | 1630        |\n",
            "|    total_timesteps      | 219136      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011132765 |\n",
            "|    clip_fraction        | 0.107       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.73       |\n",
            "|    explained_variance   | 0.195       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.7         |\n",
            "|    n_updates            | 1060        |\n",
            "|    policy_gradient_loss | -0.0242     |\n",
            "|    value_loss           | 5.52        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=220000, episode_reward=10.42 +/- 2.44\n",
            "Episode length: 2.80 +/- 0.75\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 2.8          |\n",
            "|    mean_reward          | 10.4         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 220000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0111252535 |\n",
            "|    clip_fraction        | 0.107        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.7         |\n",
            "|    explained_variance   | 0.165        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.95         |\n",
            "|    n_updates            | 1070         |\n",
            "|    policy_gradient_loss | -0.0242      |\n",
            "|    value_loss           | 8.02         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 2.69     |\n",
            "|    ep_rew_mean     | 9.63     |\n",
            "| time/              |          |\n",
            "|    fps             | 134      |\n",
            "|    iterations      | 108      |\n",
            "|    time_elapsed    | 1644     |\n",
            "|    total_timesteps | 221184   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.7         |\n",
            "|    ep_rew_mean          | 10.6        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 134         |\n",
            "|    iterations           | 109         |\n",
            "|    time_elapsed         | 1657        |\n",
            "|    total_timesteps      | 223232      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010072017 |\n",
            "|    clip_fraction        | 0.11        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.67       |\n",
            "|    explained_variance   | 0.191       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.92        |\n",
            "|    n_updates            | 1080        |\n",
            "|    policy_gradient_loss | -0.0232     |\n",
            "|    value_loss           | 8           |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 3.1         |\n",
            "|    ep_rew_mean          | 10.3        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 134         |\n",
            "|    iterations           | 110         |\n",
            "|    time_elapsed         | 1671        |\n",
            "|    total_timesteps      | 225280      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009843327 |\n",
            "|    clip_fraction        | 0.104       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.69       |\n",
            "|    explained_variance   | 0.228       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.67        |\n",
            "|    n_updates            | 1090        |\n",
            "|    policy_gradient_loss | -0.0202     |\n",
            "|    value_loss           | 5.72        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.7         |\n",
            "|    ep_rew_mean          | 9.66        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 134         |\n",
            "|    iterations           | 111         |\n",
            "|    time_elapsed         | 1684        |\n",
            "|    total_timesteps      | 227328      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011231301 |\n",
            "|    clip_fraction        | 0.0948      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.67       |\n",
            "|    explained_variance   | 0.201       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.51        |\n",
            "|    n_updates            | 1100        |\n",
            "|    policy_gradient_loss | -0.0198     |\n",
            "|    value_loss           | 6.64        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.63        |\n",
            "|    ep_rew_mean          | 9.8         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 135         |\n",
            "|    iterations           | 112         |\n",
            "|    time_elapsed         | 1698        |\n",
            "|    total_timesteps      | 229376      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011051588 |\n",
            "|    clip_fraction        | 0.112       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.64       |\n",
            "|    explained_variance   | 0.236       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.68        |\n",
            "|    n_updates            | 1110        |\n",
            "|    policy_gradient_loss | -0.0227     |\n",
            "|    value_loss           | 5.62        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=230000, episode_reward=11.41 +/- 2.21\n",
            "Episode length: 2.80 +/- 0.98\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 2.8         |\n",
            "|    mean_reward          | 11.4        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 230000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011532005 |\n",
            "|    clip_fraction        | 0.111       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.63       |\n",
            "|    explained_variance   | 0.201       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.06        |\n",
            "|    n_updates            | 1120        |\n",
            "|    policy_gradient_loss | -0.0251     |\n",
            "|    value_loss           | 7.28        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 2.78     |\n",
            "|    ep_rew_mean     | 10.6     |\n",
            "| time/              |          |\n",
            "|    fps             | 135      |\n",
            "|    iterations      | 113      |\n",
            "|    time_elapsed    | 1711     |\n",
            "|    total_timesteps | 231424   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.81         |\n",
            "|    ep_rew_mean          | 10.5         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 135          |\n",
            "|    iterations           | 114          |\n",
            "|    time_elapsed         | 1724         |\n",
            "|    total_timesteps      | 233472       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0101644285 |\n",
            "|    clip_fraction        | 0.0862       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.64        |\n",
            "|    explained_variance   | 0.237        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.64         |\n",
            "|    n_updates            | 1130         |\n",
            "|    policy_gradient_loss | -0.0204      |\n",
            "|    value_loss           | 5.98         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.75         |\n",
            "|    ep_rew_mean          | 10.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 135          |\n",
            "|    iterations           | 115          |\n",
            "|    time_elapsed         | 1737         |\n",
            "|    total_timesteps      | 235520       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0097525455 |\n",
            "|    clip_fraction        | 0.102        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | 0.232        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.44         |\n",
            "|    n_updates            | 1140         |\n",
            "|    policy_gradient_loss | -0.0222      |\n",
            "|    value_loss           | 5.53         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.93        |\n",
            "|    ep_rew_mean          | 10.2        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 135         |\n",
            "|    iterations           | 116         |\n",
            "|    time_elapsed         | 1751        |\n",
            "|    total_timesteps      | 237568      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009674738 |\n",
            "|    clip_fraction        | 0.106       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.57       |\n",
            "|    explained_variance   | 0.224       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.33        |\n",
            "|    n_updates            | 1150        |\n",
            "|    policy_gradient_loss | -0.0218     |\n",
            "|    value_loss           | 7.08        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.8         |\n",
            "|    ep_rew_mean          | 10.4        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 135         |\n",
            "|    iterations           | 117         |\n",
            "|    time_elapsed         | 1764        |\n",
            "|    total_timesteps      | 239616      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010638102 |\n",
            "|    clip_fraction        | 0.104       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.6        |\n",
            "|    explained_variance   | 0.213       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.11        |\n",
            "|    n_updates            | 1160        |\n",
            "|    policy_gradient_loss | -0.0242     |\n",
            "|    value_loss           | 7.1         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=240000, episode_reward=11.22 +/- 2.54\n",
            "Episode length: 2.20 +/- 1.17\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 2.2         |\n",
            "|    mean_reward          | 11.2        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 240000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009784441 |\n",
            "|    clip_fraction        | 0.0933      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.54       |\n",
            "|    explained_variance   | 0.224       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.67        |\n",
            "|    n_updates            | 1170        |\n",
            "|    policy_gradient_loss | -0.0237     |\n",
            "|    value_loss           | 6.35        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 2.82     |\n",
            "|    ep_rew_mean     | 10.2     |\n",
            "| time/              |          |\n",
            "|    fps             | 135      |\n",
            "|    iterations      | 118      |\n",
            "|    time_elapsed    | 1779     |\n",
            "|    total_timesteps | 241664   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.74        |\n",
            "|    ep_rew_mean          | 10.3        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 135         |\n",
            "|    iterations           | 119         |\n",
            "|    time_elapsed         | 1793        |\n",
            "|    total_timesteps      | 243712      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009521708 |\n",
            "|    clip_fraction        | 0.108       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.56       |\n",
            "|    explained_variance   | 0.214       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.84        |\n",
            "|    n_updates            | 1180        |\n",
            "|    policy_gradient_loss | -0.0218     |\n",
            "|    value_loss           | 5.84        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.96        |\n",
            "|    ep_rew_mean          | 10.3        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 135         |\n",
            "|    iterations           | 120         |\n",
            "|    time_elapsed         | 1807        |\n",
            "|    total_timesteps      | 245760      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009557796 |\n",
            "|    clip_fraction        | 0.0959      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.52       |\n",
            "|    explained_variance   | 0.253       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.95        |\n",
            "|    n_updates            | 1190        |\n",
            "|    policy_gradient_loss | -0.0224     |\n",
            "|    value_loss           | 5.87        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.96        |\n",
            "|    ep_rew_mean          | 10.3        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 136         |\n",
            "|    iterations           | 121         |\n",
            "|    time_elapsed         | 1821        |\n",
            "|    total_timesteps      | 247808      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009499419 |\n",
            "|    clip_fraction        | 0.0919      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.54       |\n",
            "|    explained_variance   | 0.206       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.05        |\n",
            "|    n_updates            | 1200        |\n",
            "|    policy_gradient_loss | -0.021      |\n",
            "|    value_loss           | 5.94        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.91        |\n",
            "|    ep_rew_mean          | 10.3        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 136         |\n",
            "|    iterations           | 122         |\n",
            "|    time_elapsed         | 1835        |\n",
            "|    total_timesteps      | 249856      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010531921 |\n",
            "|    clip_fraction        | 0.106       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.51       |\n",
            "|    explained_variance   | 0.224       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.29        |\n",
            "|    n_updates            | 1210        |\n",
            "|    policy_gradient_loss | -0.022      |\n",
            "|    value_loss           | 5.38        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=250000, episode_reward=11.91 +/- 2.68\n",
            "Episode length: 2.60 +/- 1.36\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 2.6         |\n",
            "|    mean_reward          | 11.9        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 250000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009981355 |\n",
            "|    clip_fraction        | 0.103       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.55       |\n",
            "|    explained_variance   | 0.219       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.89        |\n",
            "|    n_updates            | 1220        |\n",
            "|    policy_gradient_loss | -0.0237     |\n",
            "|    value_loss           | 5.91        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 2.79     |\n",
            "|    ep_rew_mean     | 9.85     |\n",
            "| time/              |          |\n",
            "|    fps             | 136      |\n",
            "|    iterations      | 123      |\n",
            "|    time_elapsed    | 1848     |\n",
            "|    total_timesteps | 251904   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 2.95         |\n",
            "|    ep_rew_mean          | 10.7         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 136          |\n",
            "|    iterations           | 124          |\n",
            "|    time_elapsed         | 1862         |\n",
            "|    total_timesteps      | 253952       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0093783885 |\n",
            "|    clip_fraction        | 0.104        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.5         |\n",
            "|    explained_variance   | 0.199        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.1          |\n",
            "|    n_updates            | 1230         |\n",
            "|    policy_gradient_loss | -0.0214      |\n",
            "|    value_loss           | 5.49         |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 2.91       |\n",
            "|    ep_rew_mean          | 10.7       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 136        |\n",
            "|    iterations           | 125        |\n",
            "|    time_elapsed         | 1875       |\n",
            "|    total_timesteps      | 256000     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01135167 |\n",
            "|    clip_fraction        | 0.122      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.55      |\n",
            "|    explained_variance   | 0.229      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.64       |\n",
            "|    n_updates            | 1240       |\n",
            "|    policy_gradient_loss | -0.0246    |\n",
            "|    value_loss           | 5.88       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.93        |\n",
            "|    ep_rew_mean          | 10.8        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 136         |\n",
            "|    iterations           | 126         |\n",
            "|    time_elapsed         | 1888        |\n",
            "|    total_timesteps      | 258048      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009109652 |\n",
            "|    clip_fraction        | 0.0866      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.54       |\n",
            "|    explained_variance   | 0.224       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.52        |\n",
            "|    n_updates            | 1250        |\n",
            "|    policy_gradient_loss | -0.0195     |\n",
            "|    value_loss           | 6.1         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=260000, episode_reward=9.54 +/- 2.00\n",
            "Episode length: 2.80 +/- 0.40\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 2.8         |\n",
            "|    mean_reward          | 9.54        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 260000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008459169 |\n",
            "|    clip_fraction        | 0.0853      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.47       |\n",
            "|    explained_variance   | 0.237       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.31        |\n",
            "|    n_updates            | 1260        |\n",
            "|    policy_gradient_loss | -0.0214     |\n",
            "|    value_loss           | 6.27        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 3.05     |\n",
            "|    ep_rew_mean     | 10.7     |\n",
            "| time/              |          |\n",
            "|    fps             | 136      |\n",
            "|    iterations      | 127      |\n",
            "|    time_elapsed    | 1902     |\n",
            "|    total_timesteps | 260096   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 3.03        |\n",
            "|    ep_rew_mean          | 10.2        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 136         |\n",
            "|    iterations           | 128         |\n",
            "|    time_elapsed         | 1915        |\n",
            "|    total_timesteps      | 262144      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009631496 |\n",
            "|    clip_fraction        | 0.0916      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.51       |\n",
            "|    explained_variance   | 0.214       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.62        |\n",
            "|    n_updates            | 1270        |\n",
            "|    policy_gradient_loss | -0.0225     |\n",
            "|    value_loss           | 6.59        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 3           |\n",
            "|    ep_rew_mean          | 10.2        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 136         |\n",
            "|    iterations           | 129         |\n",
            "|    time_elapsed         | 1928        |\n",
            "|    total_timesteps      | 264192      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008483704 |\n",
            "|    clip_fraction        | 0.0853      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.53       |\n",
            "|    explained_variance   | 0.205       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.9         |\n",
            "|    n_updates            | 1280        |\n",
            "|    policy_gradient_loss | -0.0218     |\n",
            "|    value_loss           | 6.48        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 3.03        |\n",
            "|    ep_rew_mean          | 10.7        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 137         |\n",
            "|    iterations           | 130         |\n",
            "|    time_elapsed         | 1942        |\n",
            "|    total_timesteps      | 266240      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009704373 |\n",
            "|    clip_fraction        | 0.103       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.46       |\n",
            "|    explained_variance   | 0.206       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.01        |\n",
            "|    n_updates            | 1290        |\n",
            "|    policy_gradient_loss | -0.0224     |\n",
            "|    value_loss           | 6.23        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 3.09        |\n",
            "|    ep_rew_mean          | 10.7        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 137         |\n",
            "|    iterations           | 131         |\n",
            "|    time_elapsed         | 1955        |\n",
            "|    total_timesteps      | 268288      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010607836 |\n",
            "|    clip_fraction        | 0.112       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.46       |\n",
            "|    explained_variance   | 0.247       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.09        |\n",
            "|    n_updates            | 1300        |\n",
            "|    policy_gradient_loss | -0.0224     |\n",
            "|    value_loss           | 6.95        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=270000, episode_reward=11.86 +/- 1.94\n",
            "Episode length: 3.00 +/- 0.63\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 3           |\n",
            "|    mean_reward          | 11.9        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 270000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006955617 |\n",
            "|    clip_fraction        | 0.0776      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.49       |\n",
            "|    explained_variance   | 0.194       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.58        |\n",
            "|    n_updates            | 1310        |\n",
            "|    policy_gradient_loss | -0.0177     |\n",
            "|    value_loss           | 6.81        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 2.95     |\n",
            "|    ep_rew_mean     | 10.4     |\n",
            "| time/              |          |\n",
            "|    fps             | 137      |\n",
            "|    iterations      | 132      |\n",
            "|    time_elapsed    | 1968     |\n",
            "|    total_timesteps | 270336   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.94        |\n",
            "|    ep_rew_mean          | 10.5        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 137         |\n",
            "|    iterations           | 133         |\n",
            "|    time_elapsed         | 1981        |\n",
            "|    total_timesteps      | 272384      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010965312 |\n",
            "|    clip_fraction        | 0.116       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.5        |\n",
            "|    explained_variance   | 0.209       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.22        |\n",
            "|    n_updates            | 1320        |\n",
            "|    policy_gradient_loss | -0.0243     |\n",
            "|    value_loss           | 6.42        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 2.85       |\n",
            "|    ep_rew_mean          | 11.1       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 137        |\n",
            "|    iterations           | 134        |\n",
            "|    time_elapsed         | 1994       |\n",
            "|    total_timesteps      | 274432     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00868257 |\n",
            "|    clip_fraction        | 0.0816     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.43      |\n",
            "|    explained_variance   | 0.211      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 3.35       |\n",
            "|    n_updates            | 1330       |\n",
            "|    policy_gradient_loss | -0.021     |\n",
            "|    value_loss           | 6.56       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.85        |\n",
            "|    ep_rew_mean          | 10.8        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 137         |\n",
            "|    iterations           | 135         |\n",
            "|    time_elapsed         | 2008        |\n",
            "|    total_timesteps      | 276480      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011237202 |\n",
            "|    clip_fraction        | 0.12        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.44       |\n",
            "|    explained_variance   | 0.222       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.14        |\n",
            "|    n_updates            | 1340        |\n",
            "|    policy_gradient_loss | -0.0228     |\n",
            "|    value_loss           | 6.52        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 3.12         |\n",
            "|    ep_rew_mean          | 10.7         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 137          |\n",
            "|    iterations           | 136          |\n",
            "|    time_elapsed         | 2021         |\n",
            "|    total_timesteps      | 278528       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0069572404 |\n",
            "|    clip_fraction        | 0.0681       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.18         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.58         |\n",
            "|    n_updates            | 1350         |\n",
            "|    policy_gradient_loss | -0.0181      |\n",
            "|    value_loss           | 5.71         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=280000, episode_reward=12.39 +/- 2.25\n",
            "Episode length: 3.00 +/- 1.10\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 3           |\n",
            "|    mean_reward          | 12.4        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 280000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009201407 |\n",
            "|    clip_fraction        | 0.107       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.41       |\n",
            "|    explained_variance   | 0.214       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.29        |\n",
            "|    n_updates            | 1360        |\n",
            "|    policy_gradient_loss | -0.0241     |\n",
            "|    value_loss           | 6.94        |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 3        |\n",
            "|    ep_rew_mean     | 10.4     |\n",
            "| time/              |          |\n",
            "|    fps             | 137      |\n",
            "|    iterations      | 137      |\n",
            "|    time_elapsed    | 2034     |\n",
            "|    total_timesteps | 280576   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.87        |\n",
            "|    ep_rew_mean          | 10.6        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 138         |\n",
            "|    iterations           | 138         |\n",
            "|    time_elapsed         | 2047        |\n",
            "|    total_timesteps      | 282624      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009348832 |\n",
            "|    clip_fraction        | 0.101       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.42       |\n",
            "|    explained_variance   | 0.225       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.28        |\n",
            "|    n_updates            | 1370        |\n",
            "|    policy_gradient_loss | -0.0222     |\n",
            "|    value_loss           | 7.09        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.93        |\n",
            "|    ep_rew_mean          | 10.7        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 138         |\n",
            "|    iterations           | 139         |\n",
            "|    time_elapsed         | 2060        |\n",
            "|    total_timesteps      | 284672      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009430042 |\n",
            "|    clip_fraction        | 0.0867      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.43       |\n",
            "|    explained_variance   | 0.227       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.07        |\n",
            "|    n_updates            | 1380        |\n",
            "|    policy_gradient_loss | -0.0203     |\n",
            "|    value_loss           | 6.25        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.95        |\n",
            "|    ep_rew_mean          | 11.2        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 138         |\n",
            "|    iterations           | 140         |\n",
            "|    time_elapsed         | 2073        |\n",
            "|    total_timesteps      | 286720      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008866427 |\n",
            "|    clip_fraction        | 0.0794      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | 0.241       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.44        |\n",
            "|    n_updates            | 1390        |\n",
            "|    policy_gradient_loss | -0.0197     |\n",
            "|    value_loss           | 6           |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.99        |\n",
            "|    ep_rew_mean          | 11          |\n",
            "| time/                   |             |\n",
            "|    fps                  | 138         |\n",
            "|    iterations           | 141         |\n",
            "|    time_elapsed         | 2086        |\n",
            "|    total_timesteps      | 288768      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008705299 |\n",
            "|    clip_fraction        | 0.0718      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.38       |\n",
            "|    explained_variance   | 0.187       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.85        |\n",
            "|    n_updates            | 1400        |\n",
            "|    policy_gradient_loss | -0.0173     |\n",
            "|    value_loss           | 5.55        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=290000, episode_reward=12.04 +/- 1.83\n",
            "Episode length: 3.60 +/- 0.80\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 3.6         |\n",
            "|    mean_reward          | 12          |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 290000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009730057 |\n",
            "|    clip_fraction        | 0.101       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.36       |\n",
            "|    explained_variance   | 0.269       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.86        |\n",
            "|    n_updates            | 1410        |\n",
            "|    policy_gradient_loss | -0.0222     |\n",
            "|    value_loss           | 5.23        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 3.15     |\n",
            "|    ep_rew_mean     | 10.5     |\n",
            "| time/              |          |\n",
            "|    fps             | 138      |\n",
            "|    iterations      | 142      |\n",
            "|    time_elapsed    | 2099     |\n",
            "|    total_timesteps | 290816   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 2.93        |\n",
            "|    ep_rew_mean          | 10.6        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 138         |\n",
            "|    iterations           | 143         |\n",
            "|    time_elapsed         | 2112        |\n",
            "|    total_timesteps      | 292864      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008145902 |\n",
            "|    clip_fraction        | 0.0949      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.34       |\n",
            "|    explained_variance   | 0.247       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.41        |\n",
            "|    n_updates            | 1420        |\n",
            "|    policy_gradient_loss | -0.0198     |\n",
            "|    value_loss           | 6.16        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 3.15        |\n",
            "|    ep_rew_mean          | 11.5        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 138         |\n",
            "|    iterations           | 144         |\n",
            "|    time_elapsed         | 2125        |\n",
            "|    total_timesteps      | 294912      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008862548 |\n",
            "|    clip_fraction        | 0.0858      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.36       |\n",
            "|    explained_variance   | 0.239       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.01        |\n",
            "|    n_updates            | 1430        |\n",
            "|    policy_gradient_loss | -0.0178     |\n",
            "|    value_loss           | 6.37        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 3.25        |\n",
            "|    ep_rew_mean          | 10.4        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 138         |\n",
            "|    iterations           | 145         |\n",
            "|    time_elapsed         | 2137        |\n",
            "|    total_timesteps      | 296960      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008581356 |\n",
            "|    clip_fraction        | 0.101       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.37       |\n",
            "|    explained_variance   | 0.236       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.12        |\n",
            "|    n_updates            | 1440        |\n",
            "|    policy_gradient_loss | -0.0198     |\n",
            "|    value_loss           | 6.82        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 3.21        |\n",
            "|    ep_rew_mean          | 11.1        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 139         |\n",
            "|    iterations           | 146         |\n",
            "|    time_elapsed         | 2150        |\n",
            "|    total_timesteps      | 299008      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009428634 |\n",
            "|    clip_fraction        | 0.0996      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.33       |\n",
            "|    explained_variance   | 0.227       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.36        |\n",
            "|    n_updates            | 1450        |\n",
            "|    policy_gradient_loss | -0.021      |\n",
            "|    value_loss           | 5.93        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=300000, episode_reward=11.54 +/- 2.96\n",
            "Episode length: 2.60 +/- 1.36\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 2.6         |\n",
            "|    mean_reward          | 11.5        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 300000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010654925 |\n",
            "|    clip_fraction        | 0.108       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | 0.272       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.17        |\n",
            "|    n_updates            | 1460        |\n",
            "|    policy_gradient_loss | -0.0224     |\n",
            "|    value_loss           | 5.88        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 3.05     |\n",
            "|    ep_rew_mean     | 10.7     |\n",
            "| time/              |          |\n",
            "|    fps             | 139      |\n",
            "|    iterations      | 147      |\n",
            "|    time_elapsed    | 2163     |\n",
            "|    total_timesteps | 301056   |\n",
            "---------------------------------\n",
            "Training complete.\n",
            "\n",
            "üßç Customer: {'budget': 0.15107207739493733, 'power_pref': 0.13839627201493798, 'family_size': 5, 'body_pref': 'mpv', 'fuel_pref': 'electric', 'patience': 4, 'strictness': {'body': np.str_('strong'), 'fuel': np.str_('strong'), 'power': np.str_('strong'), 'budget': np.str_('strong'), 'seats': np.str_('strong')}}\n",
            "Strictness: {'body': np.str_('strong'), 'fuel': np.str_('strong'), 'power': np.str_('strong'), 'budget': np.str_('strong'), 'seats': np.str_('strong')}\n",
            "Max Score: 0.7859682704165325\n",
            "\n",
            "üî• PPO suggested: Kia Carens\n",
            "\n",
            "üîé Top 5 refined:\n",
            "Tata Tigor EV ‚Äî score: 0.7859682704165325\n",
            "Renault Triber ‚Äî score: 0.7789720017598161\n",
            "Maruti Ertiga ‚Äî score: 0.7771570031031045\n",
            "Hyundai Kona EV ‚Äî score: 0.7767185702672836\n",
            "Maruti XL6 ‚Äî score: 0.7765320031031047\n",
            "\n",
            "üéØ FINAL RECOMMENDATION:\n",
            "Tata Tigor EV ‚Çπ 1300000\n",
            "\n",
            "üìò WHY THIS CAR:\n",
            "‚úñ Body type mismatch (preference = strong )\n",
            "‚úî Fuel preference matched\n",
            "‚úî Price aligns with your budget preference\n",
            "‚úî Enough seats for your family\n",
            "‚úî Power output close to desired level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_model(\n",
        "    model,\n",
        "    budget=10000000,\n",
        "    power_pref=0.9,\n",
        "    family_size=4,\n",
        "    body_pref=\"sedan\",\n",
        "    fuel_pref=\"petrol\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6bOAakMQH_B0",
        "outputId": "708d2650-3154-4edc-815d-6997c380cfa7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üßç Custom Customer: {'budget': 0.625, 'power_pref': 0.9, 'family_size': 4, 'body_pref': 'sedan', 'fuel_pref': 'petrol', 'patience': 4, 'strictness': {'body': 'strong', 'fuel': 'strong', 'budget': 'strong', 'power': 'soft', 'seats': 'strong'}}\n",
            "Max possible score: 0.9142164179104478\n",
            "\n",
            "üî• PPO suggestion: Kia Stinger GT\n",
            "\n",
            "üîé Top 5 refined:\n",
            "Kia K9 ‚Äî score: 0.9142164179104478\n",
            "Kia Stinger GT ‚Äî score: 0.8961940298507463\n",
            "Audi A8 ‚Äî score: 0.8949999999999999\n",
            "BMW 5 Series ‚Äî score: 0.8750373134328358\n",
            "BMW 3 Series ‚Äî score: 0.8551492537313432\n",
            "\n",
            "üéØ FINAL RECOMMENDATION:\n",
            "Kia K9 ‚Çπ 9000000\n",
            "\n",
            "üìò WHY THIS CAR:\n",
            "‚úî Matches your preferred body type\n",
            "‚úî Fuel preference matched\n",
            "‚úî Price aligns with your budget preference\n",
            "‚úî Enough seats for your family\n",
            "‚úñ Power output differs from preferred level\n"
          ]
        }
      ]
    }
  ]
}